{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff07a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-43dd1fc173da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#-----Step 1: Use VideoCapture in openCV-----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#-----Step 1: Use VideoCapture in openCV-----\n",
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "import time\n",
    "import webbrowser\n",
    "import os\n",
    "# import playsound from playsound\n",
    "BLINK_RATIO_THRESHOLD = 5.7\n",
    "\n",
    "#-----Step 5: Getting to know blink ratio\n",
    "\n",
    "def midpoint(point1 ,point2):\n",
    "    return (point1.x + point2.x)/2,(point1.y + point2.y)/2\n",
    "\n",
    "def euclidean_distance(point1 , point2):\n",
    "    return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "def get_blink_ratio(eye_points, facial_landmarks):\n",
    "    \n",
    "    #loading all the required points\n",
    "    corner_left  = (facial_landmarks.part(eye_points[0]).x, \n",
    "                    facial_landmarks.part(eye_points[0]).y)\n",
    "    corner_right = (facial_landmarks.part(eye_points[3]).x, \n",
    "                    facial_landmarks.part(eye_points[3]).y)\n",
    "    \n",
    "    center_top    = midpoint(facial_landmarks.part(eye_points[1]), \n",
    "                             facial_landmarks.part(eye_points[2]))\n",
    "    center_bottom = midpoint(facial_landmarks.part(eye_points[5]), \n",
    "                             facial_landmarks.part(eye_points[4]))\n",
    "\n",
    "    #calculating distance\n",
    "    horizontal_length = euclidean_distance(corner_left,corner_right)\n",
    "    vertical_length = euclidean_distance(center_top,center_bottom)\n",
    "\n",
    "    ratio = 0\n",
    "    if horizontal_length == 0:\n",
    "        ratio = 1\n",
    "    else:\n",
    "        ratio = horizontal_length / vertical_length\n",
    "\n",
    "    return ratio\n",
    "\n",
    "#livestream from the webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "'''in case of a video\n",
    "cap = cv2.VideoCapture(\"__path_of_the_video__\")'''\n",
    "\n",
    "#name of the display window in openCV\n",
    "cv2.namedWindow('BlinkDetector')\n",
    "\n",
    "#-----Step 3: Face detection with dlib-----\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#-----Step 4: Detecting Eyes using landmarks in dlib-----\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "#these landmarks are based on the image above \n",
    "left_eye_landmarks  = [36, 37, 38, 39, 40, 41]\n",
    "right_eye_landmarks = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "duration = 0\n",
    "blink = 0\n",
    "while True:\n",
    "    start = time.time()\n",
    "    #capturing frame\n",
    "    retval, frame = cap.read()\n",
    "\n",
    "    #exit the application if frame not found\n",
    "    if not retval:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break \n",
    "\n",
    "    #-----Step 2: converting image to grayscale-----\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #-----Step 3: Face detection with dlib-----\n",
    "    #detecting faces in the frame \n",
    "    faces,_,_ = detector.run(image = frame, upsample_num_times = 0, adjust_threshold = 0.0)\n",
    "\n",
    "    faceCount = len(faces)\n",
    "    #-----Step 4: Detecting Eyes using landmarks in dlib-----\n",
    "    for face in faces:\n",
    "        \n",
    "        landmarks = predictor(frame, face)\n",
    "\n",
    "        #-----Step 5: Calculating blink ratio for one eye-----\n",
    "        left_eye_ratio  = get_blink_ratio(left_eye_landmarks, landmarks)\n",
    "        right_eye_ratio = get_blink_ratio(right_eye_landmarks, landmarks)\n",
    "        blink_ratio     = (left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "        if blink_ratio > BLINK_RATIO_THRESHOLD:\n",
    "            #Blink detected! Do Something!\n",
    "            cv2.putText(frame,\"BLINKING\",(10,50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            2,(255,255,255),2,cv2.LINE_AA)\n",
    "            print('blink!')\n",
    "            blink += duration\n",
    "        else:\n",
    "            if blink > 0:\n",
    "                blink -= duration\n",
    "            else:\n",
    "                blink = 0\n",
    "\n",
    "    duration = (time.time() - start)\n",
    "    print(faceCount, duration, blink)\n",
    "    if blink >= 2:\n",
    "        print('Sleeping!!!!')\n",
    "        cv2.putText(frame,\"SLEEPING\",(10,120), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            2,(255,255,255),2,cv2.LINE_AA)\n",
    "        print('\\a')\n",
    "        blink = 0\n",
    "        # webbrowser.open('file://{}/index.html'.format(os.path.abspath(os.getcwd())))\n",
    "    # time.sleep(1)\n",
    "    cv2.imshow('BlinkDetector', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "#releasing the VideoCapture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8514e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for opencv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
